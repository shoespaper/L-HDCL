import os
import subprocess
import sys
import glob
import pandas as pd
import time
import numpy as np

# ================= 1. å®éªŒé…ç½®åŒºåŸŸ (åœ¨è¿™é‡Œä¿®æ”¹ä½ çš„å‚æ•°) =================

# ä½ æƒ³æœç´¢çš„æƒé‡åˆ—è¡¨
WEIGHTS_TO_SEARCH = [0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1]
#WEIGHTS_TO_SEARCH = np.arange(0.00, 0.1 + 0.01, 0.01).tolist() # ä» 0.00 åˆ° 0.10ï¼Œæ­¥é•¿ 0.01
# åŸºç¡€å‚æ•°é…ç½® (ä½ æƒ³è®°å½•åœ¨ CSV é‡Œçš„å‚æ•°éƒ½å†™åœ¨è¿™é‡Œ)
# è„šæœ¬ä¼šè‡ªåŠ¨å°†è¿™äº›å‚æ•°æ‹¼æ¥æˆå‘½ä»¤è¡Œï¼Œå¹¶è®°å½•åˆ°ç»“æœè¡¨ä¸­
BASE_CONFIG = {
    "dataset": "mosei",
    #"common_dim": 256,       # ä½ æƒ³è°ƒæ•´çš„ç»´åº¦
    #"layers": 2,             # Transformer å±‚æ•°
    "batch_size": 128,        # Batch Size
    #"num_epochs": 50,        # è®­ç»ƒè½®æ•°
    "lr_main": 8e-5,         # å­¦ä¹ ç‡
    "clip": 5.0,              # æ¢¯åº¦è£å‰ªé˜ˆå€¼
    "common_dim": 128,       # å…¬å…±ç©ºé—´ç»´åº¦ 
    #"dropout_prj": 0.5,    # æŠ•å½±å±‚ Dropout æ¯”ä¾‹
    #"attn_dropout": 0.2,   # æ³¨æ„åŠ› Dropout æ¯”ä¾‹

}

# ç»“æœä¿å­˜æ–‡ä»¶å
SUMMARY_FILE = "tuning_summary.csv"

# Pythonè§£é‡Šå™¨
PYTHON_EXE = sys.executable 
# ======================================================================

def get_latest_log_csv(dataset_name):
    """æ‰¾åˆ° logs/dataset/ ç›®å½•ä¸‹æœ€æ–°çš„ metrics_xxx.csv"""
    log_dir = os.path.join("logs", dataset_name)
    
    if not os.path.exists(log_dir):
        return None

    # è·å–æ‰€æœ‰ metrics_*.csv æ–‡ä»¶
    list_of_files = glob.glob(os.path.join(log_dir, "metrics_*.csv")) 
    
    if not list_of_files:
        return None
        
    # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œæ‰¾æœ€æ–°çš„
    latest_file = max(list_of_files, key=os.path.getctime)
    return latest_file

def analyze_log_file(csv_path):
    """è¯»å–å•æ¬¡è®­ç»ƒçš„ CSVï¼Œæ‰¾åˆ° Acc-2 æœ€é«˜çš„é‚£ä¸€è¡Œ"""
    try:
        # å°è¯•è¯»å–ï¼Œå¦‚æœæ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯ï¼ŒPandas ä¼šæŠ¥é”™
        df = pd.read_csv(csv_path)
        
        if df.empty or 'Test_Acc_2' not in df.columns:
            print(f"âš ï¸ æ—¥å¿—æ–‡ä»¶ {csv_path} ä¸ºç©ºæˆ–ç¼ºå°‘å…³é”®åˆ—ã€‚")
            return None
            
        # æ‰¾åˆ° Test_Acc_2 æœ€å¤§å€¼å¯¹åº”çš„ç´¢å¼•
        best_idx = df['Test_Acc_2'].idxmax()
        best_row = df.iloc[best_idx]
        
        return {
            "Best_Epoch": int(best_row['Epoch']),
            "Best_Acc2": best_row['Test_Acc_2'],
            "Best_F1": best_row['Test_F1'],
            "MAE": best_row['Test_MAE'],
            "Corr": best_row['Test_Corr']
        }
    except pd.errors.EmptyDataError:
        print(f"âš ï¸ æ—¥å¿—æ–‡ä»¶ {csv_path} æ˜¯ç©ºçš„ã€‚")
        return None
    except Exception as e:
        print(f"âŒ è¯»å–æ—¥å¿—æ–‡ä»¶å‡ºé”™ {csv_path}: {e}")
        return None

def main():
    # 1. å‡†å¤‡ CSV è¡¨å¤´
    config_keys = list(BASE_CONFIG.keys())
    result_keys = ["Best_Acc2", "Best_F1", "MAE", "Corr", "Best_Epoch"]
    # å¼ºåˆ¶å®šä¹‰åˆ—çš„é¡ºåº
    headers = ["Timestamp", "Aux_Weight"] + config_keys + result_keys + ["Log_File"]

    # åˆå§‹åŒ–æ±‡æ€»æ–‡ä»¶
    if not os.path.exists(SUMMARY_FILE):
        pd.DataFrame(columns=headers).to_csv(SUMMARY_FILE, index=False)

    print(f"ğŸš€ å¼€å§‹è‡ªåŠ¨å®éªŒã€‚å…± {len(WEIGHTS_TO_SEARCH)} ç»„å‚æ•°ã€‚")
    print(f"ğŸ“‚ ç»“æœå°†ä¿å­˜åœ¨: {SUMMARY_FILE}\n")

    for weight in WEIGHTS_TO_SEARCH:
        print(f"==================================================")
        print(f"â–¶ æ­£åœ¨è¿è¡Œ: Aux_Weight = {weight}, Config = {BASE_CONFIG}")
        print(f"==================================================")
        
        # 2. åŠ¨æ€æ„é€ å‘½ä»¤
        # åŸºç¡€å‘½ä»¤
        cmd = [PYTHON_EXE, "-m", "src.main", "--aux_weight", str(weight)]
        
        # å°† BASE_CONFIG é‡Œçš„é”®å€¼å¯¹æ‹¼æ¥åˆ°å‘½ä»¤ä¸­
        # ä¾‹å¦‚: --common_dim 256
        for key, value in BASE_CONFIG.items():
            cmd.append(f"--{key}")
            cmd.append(str(value))
        
        # æ‰“å°å®Œæ•´å‘½ä»¤ä¾›æ£€æŸ¥
        print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")

        # 3. è¿è¡Œè®­ç»ƒ
        try:
            # check=True ç¡®ä¿å¦‚æœ python main.py æŠ¥é”™ï¼Œè„šæœ¬èƒ½æ•è·å¹¶æç¤º
            subprocess.run(cmd, check=True)
        except subprocess.CalledProcessError:
            print(f"âŒ å®éªŒ (Weight={weight}) è¿è¡Œå¤±è´¥ï¼ˆExit Code != 0ï¼‰ï¼è·³è¿‡...")
            continue
        except KeyboardInterrupt:
            print("\nâ›” ç”¨æˆ·æ‰‹åŠ¨ä¸­æ–­ã€‚")
            break

        # 4. è·å–æ—¥å¿—
        latest_csv = get_latest_log_csv(BASE_CONFIG['dataset'])
        if not latest_csv:
            print("âš ï¸ æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶ï¼ˆå¯èƒ½æ˜¯è®­ç»ƒæœªå¯åŠ¨æˆ–ç›®å½•è¢«åˆ ï¼‰ï¼Œè·³è¿‡è®°å½•ã€‚")
            continue

        # 5. åˆ†æç»“æœ
        result = analyze_log_file(latest_csv)
        if result:
            print(f"âœ… å®éªŒæˆåŠŸ! Best Acc: {result['Best_Acc2']:.4f}")
            
            # 6. æ„é€ æ±‡æ€»è¡Œæ•°æ®
            row_data = {
                "Timestamp": time.strftime('%Y-%m-%d %H:%M:%S'),
                "Aux_Weight": weight,
                **BASE_CONFIG, 
                **result,      
                "Log_File": latest_csv
            }
            
            # ================= [å…³é”®ä¿®æ”¹åœ¨è¿™é‡Œ] =================
            # åˆ›å»º DataFrame æ—¶ï¼Œæ˜¾å¼ä¼ å…¥ columns=headers
            # è¿™æ · Pandas å°±ä¼šå¼ºåˆ¶æŒ‰ç…§ headers çš„é¡ºåºæ’åˆ—æ•°æ®ï¼Œç»ä¸ä¼šé”™ä½
            df_row = pd.DataFrame([row_data], columns=headers)
            
            df_row.to_csv(SUMMARY_FILE, mode='a', header=False, index=False)
            # ==================================================
        else:
            print("âš ï¸ æ— æ³•ä»æ—¥å¿—ä¸­æå–æœ‰æ•ˆç»“æœã€‚")
            
        time.sleep(1)

    print(f"\nğŸ‰ æ‰€æœ‰å®éªŒç»“æŸï¼è¯·æ‰“å¼€ {SUMMARY_FILE} æŸ¥çœ‹å¯¹æ¯”ç»“æœã€‚")

if __name__ == "__main__":
    main()